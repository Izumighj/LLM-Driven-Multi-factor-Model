{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "c000ee7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功连接到 MongoDB。\n",
      "数据筛选范围: 20200101 到 20251018\n",
      "\n",
      "正在为指数 '000300.SH' 查找最新交易日期...\n",
      "-> 找到最新交易日期: 20251009\n",
      "正在从 'index_components' 加载数据...\n",
      "-> 成功加载 300 行数据。\n",
      "\n",
      "共获取 300 只成分股。\n",
      "正在从 'daily_prices' 加载数据...\n",
      "-> 成功加载 404,561 行数据。\n",
      "正在从 'cashflow' 加载数据...\n",
      "-> 成功加载 11,142 行数据。\n",
      "正在从 'financial_indicators' 加载数据...\n",
      "-> 成功加载 7,686 行数据。\n",
      "正在从 'balancesheet' 加载数据...\n",
      "-> 成功加载 10,389 行数据。\n",
      "正在从 'index_daily_prices' 加载数据...\n",
      "-> 成功加载 1,402 行数据。\n",
      "现金流数据去重处理与日期处理完毕\n",
      "资产负债表数据去重处理与日期处理完毕\n",
      "财务指标数据日期处理完毕\n",
      "日线行情数据日期处理完毕\n",
      "指数行情数据日期处理完毕\n"
     ]
    }
   ],
   "source": [
    "# 从 Mongodb 数据库中加载数据\n",
    "\n",
    "# 导入所需的库\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient, DESCENDING # 导入 DESCENDING 用于排序\n",
    "from tqdm import tqdm # 在 Jupyter 中使用 tqdm.notebook 获得更好的进度条体验\n",
    "from datetime import date\n",
    "# 配置数据库连接信息\n",
    "\n",
    "MONGO_CONNECTION_STRING = \"mongodb://localhost:27017/\"\n",
    "DB_NAME = \"barra_financial_data\"\n",
    "\n",
    "\n",
    "# 创建一个辅助函数，用于将集合加载到 DataFrame\n",
    "\n",
    "def load_collection_to_df(db, collection_name: str, query: dict, projection: dict) -> pd.DataFrame:\n",
    "    \"\"\"加载经过筛选和投影的集合数据。\"\"\"\n",
    "    print(f\"正在从 '{collection_name}' 加载数据...\")\n",
    "    collection = db[collection_name]\n",
    "    cursor = collection.find(query, projection)\n",
    "    df = pd.DataFrame(list(cursor))\n",
    "    print(f\"-> 成功加载 {len(df):,} 行数据。\")\n",
    "    return df\n",
    "\n",
    "# 连接到数据库\n",
    "client = MongoClient(MONGO_CONNECTION_STRING)\n",
    "db = client[DB_NAME]\n",
    "print(\"成功连接到 MongoDB。\")\n",
    "\n",
    "\n",
    "# 定义查询时间\n",
    "start_date_str = \"20200101\"  # 股票日线开始日期\n",
    "start_date_financial_str = \"20190101\"  # 财务数据开始日期\n",
    "end_date_str = date.today().strftime('%Y%m%d')\n",
    "print(f\"数据筛选范围: {start_date_str} 到 {end_date_str}\")\n",
    "\n",
    "\n",
    "# 选择想要查询的股票池，如：沪深300、上证50等\n",
    "\n",
    "# 首先连接到指数成分股集合，获取成分股列表\n",
    "index_components_collection_name = \"index_components\" #\n",
    "index_code = \"000300.SH\"\n",
    "\n",
    "# 1. 查找最新的交易日期\n",
    "print(f\"\\n正在为指数 '{index_code}' 查找最新交易日期...\")\n",
    "collection = db[index_components_collection_name]\n",
    "\n",
    "# 使用 find_one() 配合 sort 可以高效地找到一个文档\n",
    "latest_entry = collection.find_one(\n",
    "    {\"index_code\": index_code},      # 筛选条件\n",
    "    sort=[(\"trade_date\", DESCENDING)]       # 按 trade_date 降序排列\n",
    ")\n",
    "\n",
    "# 检查是否找到了数据\n",
    "if latest_entry:\n",
    "    latest_trade_date = latest_entry['trade_date']\n",
    "    print(f\"-> 找到最新交易日期: {latest_trade_date}\")\n",
    "\n",
    "    # 2. 使用找到的最新日期来查询所有成分股\n",
    "    index_info_query = {\n",
    "        \"index_code\": index_code,\n",
    "        \"trade_date\": latest_trade_date  # 使用动态获取的日期\n",
    "    }\n",
    "    index_info_projection = {\"con_code\": 1, \"_id\": 0}\n",
    "\n",
    "    # 调用你的辅助函数加载数据\n",
    "    index_constituents_df = load_collection_to_df(\n",
    "        db,\n",
    "        collection_name=index_components_collection_name,\n",
    "        query=index_info_query,\n",
    "        projection=index_info_projection\n",
    "    )\n",
    "\n",
    "    \n",
    "    constituent_list = index_constituents_df['con_code'].tolist()\n",
    "    print(f\"\\n共获取 {len(constituent_list)} 只成分股。\")\n",
    "\n",
    "else:\n",
    "    print(f\"!! 未能在集合 '{index_components_collection_name}' 中找到指数 '{index_code}' 的任何记录。\")\n",
    "\n",
    "# 根据成分股列表，加载所需的股票数据\n",
    "# 日线行情：close, total_mv, pb, turnover_rate, pe_ttm, circ_mv\n",
    "\n",
    "daily_prices_query = {\n",
    "    \"ts_code\": {\"$in\": constituent_list},\n",
    "    \"trade_date\": {\"$gte\": start_date_str, \"$lte\": end_date_str}\n",
    "}\n",
    "\n",
    "daily_prices_projection = {\n",
    "    \"ts_code\": 1,\n",
    "    \"trade_date\": 1,\n",
    "    \"close\": 1,\n",
    "    \"total_mv\": 1,\n",
    "    \"circ_mv\": 1,\n",
    "    \"pb\": 1,\n",
    "    \"turnover_rate\": 1,\n",
    "    \"pe_ttm\": 1,\n",
    "    \"_id\": 0\n",
    "}\n",
    "\n",
    "daily_prices_df = load_collection_to_df(\n",
    "    db,\n",
    "    collection_name=\"daily_prices\",\n",
    "    query=daily_prices_query,\n",
    "    projection=daily_prices_projection\n",
    ")\n",
    "\n",
    "\n",
    "# 现金流量：n_cashflow_act \n",
    "cashflow_query = {\n",
    "    \"ts_code\": {\"$in\": constituent_list},\n",
    "    \"end_date\": {\"$gte\": start_date_financial_str, \"$lte\": end_date_str}\n",
    "}\n",
    "\n",
    "cashflow_projection = {\n",
    "    \"ts_code\": 1,\n",
    "    \"ann_date\": 1,\n",
    "    \"f_ann_date\": 1,\n",
    "    \"end_date\": 1,\n",
    "    \"n_cashflow_act\": 1,\n",
    "    \"_id\": 0\n",
    "}\n",
    "\n",
    "cashflow_df = load_collection_to_df(\n",
    "    db,\n",
    "    collection_name=\"cashflow\",\n",
    "    query=cashflow_query,\n",
    "    projection=cashflow_projection\n",
    ")\n",
    "\n",
    "\n",
    "# 财务指标： 'q_profit_yoy', 'q_sales_yoy', debt_to_assets\n",
    "financial_indicators_query = {\n",
    "    \"ts_code\": {\"$in\": constituent_list},\n",
    "    \"end_date\": {\"$gte\": start_date_financial_str, \"$lte\": end_date_str}\n",
    "}\n",
    "\n",
    "financial_indicators_projection = {\n",
    "    \"ts_code\": 1,\n",
    "    \"ann_date\": 1, \n",
    "    \"end_date\": 1,\n",
    "    \"q_profit_yoy\": 1,\n",
    "    \"q_sales_yoy\": 1,\n",
    "    \"debt_to_assets\": 1,\n",
    "    \"_id\": 0\n",
    "}\n",
    "\n",
    "financial_indicators_df = load_collection_to_df(\n",
    "    db,\n",
    "    collection_name=\"financial_indicators\",\n",
    "    query=financial_indicators_query,\n",
    "    projection=financial_indicators_projection\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 资产负债表： total_ncl, total_hldr_eqy_inc_min_int, \n",
    "balance_sheet_query = {\n",
    "    \"ts_code\": {\"$in\": constituent_list},\n",
    "    \"end_date\": {\"$gte\": start_date_financial_str, \"$lte\": end_date_str}\n",
    "}\n",
    "balance_sheet_projection = {\n",
    "    \"ts_code\": 1,\n",
    "    \"f_ann_date\": 1,\n",
    "    \"end_date\": 1,\n",
    "    \"total_ncl\": 1,\n",
    "    \"total_hldr_eqy_inc_min_int\": 1,\n",
    "    \"_id\": 0\n",
    "}\n",
    "balance_sheet_df = load_collection_to_df(\n",
    "    db,\n",
    "    collection_name=\"balancesheet\",\n",
    "    query=balance_sheet_query,\n",
    "    projection=balance_sheet_projection \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# 指数数据: close\n",
    "\n",
    "index_prices_query = {\n",
    "    \"ts_code\": index_code,\n",
    "    \"trade_date\": {\"$gte\": start_date_str, \"$lte\": end_date_str}            \n",
    "}\n",
    "\n",
    "index_prices_projection = {\n",
    "    \"ts_code\": 1,\n",
    "    \"trade_date\": 1,\n",
    "    \"close\": 1,\n",
    "    \"_id\": 0\n",
    "}\n",
    "\n",
    "index_prices_df = load_collection_to_df(\n",
    "    db,\n",
    "    collection_name=\"index_daily_prices\",\n",
    "    query=index_prices_query,\n",
    "    projection=index_prices_projection\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 获取数据完毕后，将数据合并，涉及到时间格式\n",
    "\n",
    "# 首先对财务数据去重\n",
    "cashflow_processed_df = cashflow_df.copy()\n",
    "cashflow_processed_df['f_ann_date'] = pd.to_datetime(cashflow_processed_df['f_ann_date'], format='%Y%m%d')\n",
    "cashflow_processed_df['end_date'] = pd.to_datetime(cashflow_processed_df['end_date'], format='%Y%m%d')\n",
    "\n",
    "# 先排序（按 f_ann_date 降序保留最新），然后去重保留第一条\n",
    "cashflow_processed_df = cashflow_processed_df.sort_values(\n",
    "    ['ts_code', 'end_date', 'f_ann_date'],\n",
    "    ascending=[True, True, False]  # f_ann_date 降序，最新在前\n",
    ").drop_duplicates(subset=['ts_code', 'end_date'], keep='first')\n",
    "\n",
    "# 这次按照 end_date 降序，保留报告期最新的\n",
    "cashflow_processed_df= cashflow_processed_df.sort_values(\n",
    "    ['ts_code', 'f_ann_date', 'end_date'],\n",
    "    ascending=[True, True, False]  # end_date 降序，最新在前\n",
    ").drop_duplicates(subset=['ts_code', 'f_ann_date'], keep='first')\n",
    "\n",
    "print('现金流数据去重处理与日期处理完毕')\n",
    "\n",
    "balance_sheet_processed_df = balance_sheet_df.copy()\n",
    "\n",
    "balance_sheet_processed_df['f_ann_date'] = pd.to_datetime(balance_sheet_processed_df['f_ann_date'], format='%Y%m%d')\n",
    "balance_sheet_processed_df['end_date'] = pd.to_datetime(balance_sheet_processed_df['end_date'], format='%Y%m%d')\n",
    "\n",
    "# 先排序（按 f_ann_date 降序保留最新），然后去重保留第一条\n",
    "balance_sheet_processed_df = balance_sheet_processed_df.sort_values(\n",
    "    ['ts_code', 'end_date', 'f_ann_date'],\n",
    "    ascending=[True, True, False]  # f_ann_date 降序，最新在前\n",
    ").drop_duplicates(subset=['ts_code', 'end_date'], keep='first')\n",
    "\n",
    "balance_sheet_processed_df= balance_sheet_processed_df.sort_values(\n",
    "    ['ts_code', 'f_ann_date', 'end_date'],\n",
    "    ascending=[True, True, False]  # end_date 降序，最新在前\n",
    ").drop_duplicates(subset=['ts_code', 'f_ann_date'], keep='first')\n",
    "\n",
    "print('资产负债表数据去重处理与日期处理完毕')\n",
    "\n",
    "financial_indicators_processed_df = financial_indicators_df.copy()\n",
    "\n",
    "financial_indicators_processed_df['ann_date'] = pd.to_datetime(financial_indicators_processed_df['ann_date'], format='%Y%m%d')\n",
    "financial_indicators_processed_df['end_date'] = pd.to_datetime(financial_indicators_processed_df['end_date'], format='%Y%m%d')\n",
    "\n",
    "financial_indicators_processed_df = financial_indicators_processed_df.sort_values(\n",
    "    ['ts_code', 'ann_date', 'end_date'],\n",
    "    ascending=[True, True, False]  # end_date 降序，最新在前\n",
    ").drop_duplicates(subset=['ts_code', 'ann_date'], keep='first')\n",
    "\n",
    "print('财务指标数据日期处理完毕')\n",
    "\n",
    "daily_prices_processed_df = daily_prices_df.copy()\n",
    "daily_prices_processed_df['trade_date'] = pd.to_datetime(daily_prices_processed_df['trade_date'], format='%Y%m%d')\n",
    "\n",
    "print('日线行情数据日期处理完毕')\n",
    "\n",
    "index_prices_processed_df = index_prices_df.copy()\n",
    "index_prices_processed_df['trade_date'] = pd.to_datetime(index_prices_processed_df['trade_date'], format='%Y%m%d')\n",
    "print('指数行情数据日期处理完毕')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "16bf69f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cashflow_processed_df= cashflow_processed_df.sort_values(\n",
    "    ['ts_code', 'f_ann_date', 'end_date'],\n",
    "    ascending=[True, True, False]  # end_date 降序，最新在前\n",
    ").drop_duplicates(subset=['ts_code', 'f_ann_date'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "94b7132d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cashflow_processed_df[cashflow_processed_df['update_flag'] == '0'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "297d8a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在 financial_indicators 中找到了 0 个 (ts_code, f_ann_date) 的重复项。\n"
     ]
    }
   ],
   "source": [
    "# 检查重复项的数量\n",
    "duplicate_count = x.duplicated(subset=['ts_code', 'f_ann_date']).sum()\n",
    "print(f\"在 financial_indicators 中找到了 {duplicate_count} 个 (ts_code, f_ann_date) 的重复项。\")\n",
    "\n",
    "# 如果想查看具体的重复行\n",
    "if duplicate_count > 0:\n",
    "    duplicates = x[x.duplicated(subset=['ts_code', 'f_ann_date'], keep=False)]\n",
    "    print(\"\\n以下是具体的重复数据示例：\")\n",
    "    print(duplicates.sort_values(by=['ts_code', 'f_ann_date']).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f92f41ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_code</th>\n",
       "      <th>ann_date</th>\n",
       "      <th>f_ann_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>n_cashflow_act</th>\n",
       "      <th>update_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>20190424</td>\n",
       "      <td>2019-04-24</td>\n",
       "      <td>2019-03-31</td>\n",
       "      <td>5.318400e+10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>20190808</td>\n",
       "      <td>2019-08-08</td>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>2.643200e+10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>20191022</td>\n",
       "      <td>2019-10-22</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>8.448000e+10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>20200214</td>\n",
       "      <td>2020-02-14</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>-4.002500e+10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>20200421</td>\n",
       "      <td>2020-04-21</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>1.798900e+10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>20200828</td>\n",
       "      <td>2020-08-28</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>-2.566600e+10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>20201022</td>\n",
       "      <td>2020-10-22</td>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>3.069800e+10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>20210202</td>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>-1.616100e+10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>20210421</td>\n",
       "      <td>2021-04-21</td>\n",
       "      <td>2021-03-31</td>\n",
       "      <td>-1.155300e+10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>20210820</td>\n",
       "      <td>2021-08-20</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>-1.159720e+11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>20211021</td>\n",
       "      <td>2021-10-21</td>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>-1.258080e+11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>20220310</td>\n",
       "      <td>2022-03-10</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>-1.927330e+11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>20220427</td>\n",
       "      <td>2022-04-27</td>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>1.471270e+11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>20220818</td>\n",
       "      <td>2022-08-18</td>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>1.504830e+11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>20221025</td>\n",
       "      <td>2022-10-25</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>9.251800e+10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>20230309</td>\n",
       "      <td>2023-03-09</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>1.345720e+11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>20230425</td>\n",
       "      <td>2023-04-25</td>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>1.091560e+11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>20230824</td>\n",
       "      <td>2023-08-24</td>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>4.424100e+10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>20231025</td>\n",
       "      <td>2023-10-25</td>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>1.159300e+11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>20240315</td>\n",
       "      <td>2024-03-15</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>9.246100e+10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>20240420</td>\n",
       "      <td>2024-04-20</td>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>-2.138200e+10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>20240816</td>\n",
       "      <td>2024-08-16</td>\n",
       "      <td>2024-06-30</td>\n",
       "      <td>1.137220e+11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>20241019</td>\n",
       "      <td>2024-10-19</td>\n",
       "      <td>2024-09-30</td>\n",
       "      <td>1.371580e+11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>20250315</td>\n",
       "      <td>2025-03-15</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>6.333600e+10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>20250419</td>\n",
       "      <td>2025-04-19</td>\n",
       "      <td>2025-03-31</td>\n",
       "      <td>1.629460e+11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>20250823</td>\n",
       "      <td>2025-08-23</td>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>1.746820e+11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ts_code  ann_date f_ann_date   end_date  n_cashflow_act update_flag\n",
       "33  000001.SZ  20190424 2019-04-24 2019-03-31    5.318400e+10           0\n",
       "32  000001.SZ  20190808 2019-08-08 2019-06-30    2.643200e+10           1\n",
       "31  000001.SZ  20191022 2019-10-22 2019-09-30    8.448000e+10           0\n",
       "29  000001.SZ  20200214 2020-02-14 2019-12-31   -4.002500e+10           0\n",
       "28  000001.SZ  20200421 2020-04-21 2020-03-31    1.798900e+10           0\n",
       "26  000001.SZ  20200828 2020-08-28 2020-06-30   -2.566600e+10           1\n",
       "25  000001.SZ  20201022 2020-10-22 2020-09-30    3.069800e+10           1\n",
       "23  000001.SZ  20210202 2021-02-02 2020-12-31   -1.616100e+10           1\n",
       "22  000001.SZ  20210421 2021-04-21 2021-03-31   -1.155300e+10           0\n",
       "21  000001.SZ  20210820 2021-08-20 2021-06-30   -1.159720e+11           0\n",
       "20  000001.SZ  20211021 2021-10-21 2021-09-30   -1.258080e+11           0\n",
       "18  000001.SZ  20220310 2022-03-10 2021-12-31   -1.927330e+11           0\n",
       "17  000001.SZ  20220427 2022-04-27 2022-03-31    1.471270e+11           0\n",
       "15  000001.SZ  20220818 2022-08-18 2022-06-30    1.504830e+11           1\n",
       "14  000001.SZ  20221025 2022-10-25 2022-09-30    9.251800e+10           0\n",
       "12  000001.SZ  20230309 2023-03-09 2022-12-31    1.345720e+11           1\n",
       "11  000001.SZ  20230425 2023-04-25 2023-03-31    1.091560e+11           0\n",
       "10  000001.SZ  20230824 2023-08-24 2023-06-30    4.424100e+10           1\n",
       "9   000001.SZ  20231025 2023-10-25 2023-09-30    1.159300e+11           0\n",
       "7   000001.SZ  20240315 2024-03-15 2023-12-31    9.246100e+10           0\n",
       "6   000001.SZ  20240420 2024-04-20 2024-03-31   -2.138200e+10           0\n",
       "5   000001.SZ  20240816 2024-08-16 2024-06-30    1.137220e+11           0\n",
       "4   000001.SZ  20241019 2024-10-19 2024-09-30    1.371580e+11           0\n",
       "2   000001.SZ  20250315 2025-03-15 2024-12-31    6.333600e+10           0\n",
       "1   000001.SZ  20250419 2025-04-19 2025-03-31    1.629460e+11           0\n",
       "0   000001.SZ  20250823 2025-08-23 2025-06-30    1.746820e+11           0"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cashflow_processed_df[cashflow_processed_df['ts_code']=='000001.SZ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "0b648954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并数据\n",
    "daily_prices_processed_df = daily_prices_processed_df.sort_values(by=['trade_date'])\n",
    "balance_sheet_processed_df = balance_sheet_processed_df.sort_values(by='f_ann_date')\n",
    "financial_indicators_processed_df = financial_indicators_processed_df.sort_values(by='ann_date')\n",
    "cashflow_processed_df = cashflow_processed_df.sort_values(by='f_ann_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0c09b104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在 financial_indicators_processed_df 中找到了 0 个 (ts_code, ann_date) 的重复项。\n"
     ]
    }
   ],
   "source": [
    "# 检查重复项的数量\n",
    "duplicate_count = financial_indicators_processed_df.duplicated(subset=['ts_code', 'ann_date']).sum()\n",
    "print(f\"在 financial_indicators_processed_df 中找到了 {duplicate_count} 个 (ts_code, ann_date) 的重复项。\")\n",
    "\n",
    "# 如果想查看具体的重复行\n",
    "if duplicate_count > 0:\n",
    "    duplicates = financial_indicators_processed_df[financial_indicators_processed_df.duplicated(subset=['ts_code', 'ann_date'], keep=False)]\n",
    "    print(\"\\n以下是具体的重复数据示例：\")\n",
    "    print(duplicates.sort_values(by=['ts_code', 'f_ann_date']).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4e6f1ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_code</th>\n",
       "      <th>f_ann_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>total_ncl</th>\n",
       "      <th>total_hldr_eqy_inc_min_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>2019-04-24</td>\n",
       "      <td>2019-03-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.509380e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>2019-08-08</td>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.566030e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>2019-10-22</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.880730e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>2020-02-14</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.129830e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>2020-04-21</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.523550e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10362</th>\n",
       "      <td>688981.SH</td>\n",
       "      <td>2024-08-30</td>\n",
       "      <td>2024-06-30</td>\n",
       "      <td>6.415649e+10</td>\n",
       "      <td>2.207147e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10361</th>\n",
       "      <td>688981.SH</td>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>2024-09-30</td>\n",
       "      <td>6.249007e+10</td>\n",
       "      <td>2.202995e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10360</th>\n",
       "      <td>688981.SH</td>\n",
       "      <td>2025-03-28</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>6.276304e+10</td>\n",
       "      <td>2.291078e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10359</th>\n",
       "      <td>688981.SH</td>\n",
       "      <td>2025-05-09</td>\n",
       "      <td>2025-03-31</td>\n",
       "      <td>6.154068e+10</td>\n",
       "      <td>2.312315e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10357</th>\n",
       "      <td>688981.SH</td>\n",
       "      <td>2025-08-29</td>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>6.755544e+10</td>\n",
       "      <td>2.345195e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6975 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ts_code f_ann_date   end_date     total_ncl  \\\n",
       "37     000001.SZ 2019-04-24 2019-03-31           NaN   \n",
       "36     000001.SZ 2019-08-08 2019-06-30           NaN   \n",
       "35     000001.SZ 2019-10-22 2019-09-30           NaN   \n",
       "33     000001.SZ 2020-02-14 2019-12-31           NaN   \n",
       "32     000001.SZ 2020-04-21 2020-03-31           NaN   \n",
       "...          ...        ...        ...           ...   \n",
       "10362  688981.SH 2024-08-30 2024-06-30  6.415649e+10   \n",
       "10361  688981.SH 2024-11-08 2024-09-30  6.249007e+10   \n",
       "10360  688981.SH 2025-03-28 2024-12-31  6.276304e+10   \n",
       "10359  688981.SH 2025-05-09 2025-03-31  6.154068e+10   \n",
       "10357  688981.SH 2025-08-29 2025-06-30  6.755544e+10   \n",
       "\n",
       "       total_hldr_eqy_inc_min_int  \n",
       "37                   2.509380e+11  \n",
       "36                   2.566030e+11  \n",
       "35                   2.880730e+11  \n",
       "33                   3.129830e+11  \n",
       "32                   3.523550e+11  \n",
       "...                           ...  \n",
       "10362                2.207147e+11  \n",
       "10361                2.202995e+11  \n",
       "10360                2.291078e+11  \n",
       "10359                2.312315e+11  \n",
       "10357                2.345195e+11  \n",
       "\n",
       "[6975 rows x 5 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balance_sheet_processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "7b6f1200",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_prices_processed_df = daily_prices_processed_df.sort_values(by=['ts_code', 'trade_date'])\n",
    "balance_sheet_processed_df = balance_sheet_processed_df.sort_values(by=['ts_code', 'f_ann_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c896ac40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 正在对左表 (daily_prices_processed_df) 进行最终诊断 ---\n",
      "关键列空值数量:\n",
      " ts_code       0\n",
      "trade_date    0\n",
      "dtype: int64\n",
      "\n",
      "关键列数据类型:\n",
      "ts_code               object\n",
      "trade_date    datetime64[ns]\n",
      "dtype: object\n",
      "\n",
      "[✓] 诊断结果: 未在关键列发现空值。\n"
     ]
    }
   ],
   "source": [
    "# 在 merge_asof 之前进行最终检查\n",
    "print(\"--- 正在对左表 (daily_prices_processed_df) 进行最终诊断 ---\")\n",
    "\n",
    "# 1. 检查关键列是否存在空值\n",
    "null_check = daily_prices_processed_df[['ts_code', 'trade_date']].isnull().sum()\n",
    "print(\"关键列空值数量:\\n\", null_check)\n",
    "\n",
    "# 2. 检查关键列的数据类型\n",
    "print(\"\\n关键列数据类型:\")\n",
    "print(daily_prices_processed_df[['ts_code', 'trade_date']].dtypes)\n",
    "\n",
    "if null_check.sum() > 0:\n",
    "    print(\"\\n[!] 诊断结果: 发现空值！这是导致排序错误的极高概率原因。\")\n",
    "    # (可选) 展示存在空值的行，以便定位\n",
    "    # print(\"存在空值的行示例:\")\n",
    "    # print(daily_prices_processed_df[daily_prices_processed_df['ts_code'].isnull() | daily_prices_processed_df['trade_date'].isnull()])\n",
    "else:\n",
    "    print(\"\\n[✓] 诊断结果: 未在关键列发现空值。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d537ba3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 排序验证 ---\n",
      "左表 (daily_prices) 是否在每个ts_code内都按trade_date正确排序? -> True\n"
     ]
    }
   ],
   "source": [
    "# 确保你已经执行了排序\n",
    "daily_prices_processed_df = daily_prices_processed_df.sort_values(by=['ts_code', 'trade_date'])\n",
    "\n",
    "# 程序化验证排序是否在每个分组内都正确\n",
    "is_left_sorted = daily_prices_processed_df.groupby('ts_code')['trade_date'].is_monotonic_increasing.all()\n",
    "\n",
    "print(f\"\\n--- 排序验证 ---\")\n",
    "print(f\"左表 (daily_prices) 是否在每个ts_code内都按trade_date正确排序? -> {is_left_sorted}\")\n",
    "\n",
    "if not is_left_sorted:\n",
    "    print(\"\\n[!] 验证失败: 左表排序不满足 merge_asof 的要求。\")\n",
    "    # 找出排序有问题的股票代码，帮助进一步分析\n",
    "    bad_groups = daily_prices_processed_df.groupby('ts_code')['trade_date'].is_monotonic_increasing\n",
    "    problematic_codes = bad_groups[~bad_groups].index.unique().tolist()\n",
    "    print(f\"排序有问题的股票代码 (前5个): {problematic_codes[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e3c75ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 正在对右表 (balance_sheet_processed_df) 进行最终诊断 ---\n",
      "关键列空值数量:\n",
      " ts_code       0\n",
      "f_ann_date    0\n",
      "dtype: int64\n",
      "\n",
      "关键列数据类型:\n",
      "ts_code               object\n",
      "f_ann_date    datetime64[ns]\n",
      "dtype: object\n",
      "\n",
      "[✓] 诊断结果: 未在右表关键列发现空值。\n",
      "\n",
      "--- 右表排序验证 ---\n",
      "右表 (balance_sheet) 是否在每个ts_code内都按f_ann_date正确排序? -> True\n"
     ]
    }
   ],
   "source": [
    "# --- 正在对右表 (balance_sheet_processed_df) 进行最终诊断 ---\n",
    "print(\"--- 正在对右表 (balance_sheet_processed_df) 进行最终诊断 ---\")\n",
    "\n",
    "# 1. 检查关键列是否存在空值\n",
    "null_check_right = balance_sheet_processed_df[['ts_code', 'f_ann_date']].isnull().sum()\n",
    "print(\"关键列空值数量:\\n\", null_check_right)\n",
    "\n",
    "# 2. 检查关键列的数据类型\n",
    "print(\"\\n关键列数据类型:\")\n",
    "print(balance_sheet_processed_df[['ts_code', 'f_ann_date']].dtypes)\n",
    "\n",
    "if null_check_right.sum() > 0:\n",
    "    print(\"\\n[!] 诊断结果: 在右表中发现空值！这很可能是根本原因。\")\n",
    "else:\n",
    "    print(\"\\n[✓] 诊断结果: 未在右表关键列发现空值。\")\n",
    "\n",
    "\n",
    "# --- 对右表进行排序验证 ---\n",
    "# 确保你已经执行了排序\n",
    "balance_sheet_processed_df = balance_sheet_processed_df.sort_values(by=['ts_code', 'f_ann_date'])\n",
    "\n",
    "# 程序化验证排序是否在每个分组内都正确\n",
    "is_right_sorted = balance_sheet_processed_df.groupby('ts_code')['f_ann_date'].is_monotonic_increasing.all()\n",
    "\n",
    "print(f\"\\n--- 右表排序验证 ---\")\n",
    "print(f\"右表 (balance_sheet) 是否在每个ts_code内都按f_ann_date正确排序? -> {is_right_sorted}\")\n",
    "\n",
    "if not is_right_sorted:\n",
    "    print(\"\\n[!] 验证失败: 右表排序不满足 merge_asof 的要求。\")\n",
    "    # 找出排序有问题的股票代码\n",
    "    bad_groups_right = balance_sheet_processed_df.groupby('ts_code')['f_ann_date'].is_monotonic_increasing\n",
    "    problematic_codes_right = bad_groups_right[~bad_groups_right].index.unique().tolist()\n",
    "    print(f\"排序有问题的股票代码 (前5个): {problematic_codes_right[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "0d2e37d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting isolation test for 300 unique stock codes...\n",
      "  ... successfully processed 100 / 300 stocks\n",
      "  ... successfully processed 200 / 300 stocks\n",
      "  ... successfully processed 300 / 300 stocks\n",
      "\n",
      "✅ All stocks processed successfully individually.\n",
      "Final DataFrame created successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- Final Isolation Debugging ---\n",
    "\n",
    "# Ensure both dataframes are fully sanitized and sorted one last time\n",
    "daily_prices_processed_df = daily_prices_processed_df.reset_index(drop=True).sort_values(by=['ts_code', 'trade_date'])\n",
    "balance_sheet_processed_df = balance_sheet_processed_df.reset_index(drop=True).sort_values(by=['ts_code', 'f_ann_date'])\n",
    "\n",
    "# Get a unique list of all stock codes to iterate over\n",
    "all_ts_codes = daily_prices_processed_df['ts_code'].unique()\n",
    "problematic_code = None\n",
    "merged_chunks = []\n",
    "\n",
    "print(f\"Starting isolation test for {len(all_ts_codes)} unique stock codes...\")\n",
    "\n",
    "for i, code in enumerate(all_ts_codes):\n",
    "    # Create small, single-stock dataframes\n",
    "    left_chunk = daily_prices_processed_df[daily_prices_processed_df['ts_code'] == code]\n",
    "    right_chunk = balance_sheet_processed_df[balance_sheet_processed_df['ts_code'] == code]\n",
    "    \n",
    "    # Skip if there's no financial data for this stock\n",
    "    if right_chunk.empty:\n",
    "        merged_chunks.append(left_chunk) # Append the daily data directly\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # Attempt the merge on this single stock\n",
    "        merged_chunk = pd.merge_asof(\n",
    "            left=left_chunk,\n",
    "            right=right_chunk,\n",
    "            left_on='trade_date',\n",
    "            right_on='f_ann_date',\n",
    "            by='ts_code',\n",
    "            direction='backward'\n",
    "        )\n",
    "        merged_chunks.append(merged_chunk)\n",
    "        \n",
    "        # Progress indicator\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"  ... successfully processed {i + 1} / {len(all_ts_codes)} stocks\")\n",
    "\n",
    "    except ValueError as e:\n",
    "        # If it fails, we have found the culprit!\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"❌ FAILURE DETECTED!\")\n",
    "        print(f\"The merge failed on ts_code: '{code}'\")\n",
    "        print(f\"Error message: {e}\")\n",
    "        problematic_code = code\n",
    "        \n",
    "        # Print the data for the failing stock for inspection\n",
    "        print(\"\\n--- Data for failing left_chunk (Daily Prices) ---\")\n",
    "        print(left_chunk)\n",
    "        print(\"\\n--- Data for failing right_chunk (Balance Sheet) ---\")\n",
    "        print(right_chunk)\n",
    "        print(\"=\"*50)\n",
    "        break # Stop the loop\n",
    "\n",
    "if problematic_code is None:\n",
    "    print(\"\\n✅ All stocks processed successfully individually.\")\n",
    "    # If the loop completes, we can safely combine the results\n",
    "    final_merged_df = pd.concat(merged_chunks, ignore_index=True)\n",
    "    print(\"Final DataFrame created successfully.\")\n",
    "else:\n",
    "    print(\"\\nPlease inspect the data printed above for the problematic stock code.\")\n",
    "    print(\"Look for duplicate dates, strange values, or anything unusual.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "7918ad7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Performing robust merge_asof on 'ts_code' ---\n",
      "Robust merge successful.\n",
      "--- Performing robust merge_asof on 'ts_code' ---\n",
      "Robust merge successful.\n",
      "--- Performing robust merge_asof on 'ts_code' ---\n",
      "Robust merge successful.\n"
     ]
    }
   ],
   "source": [
    "def robust_merge_asof(left_df, right_df, left_on, right_on, by):\n",
    "    \"\"\"\n",
    "    A robust version of pd.merge_asof that merges group by group\n",
    "    to avoid potential bugs with large DataFrames.\n",
    "    \"\"\"\n",
    "    print(f\"--- Performing robust merge_asof on '{by}' ---\")\n",
    "    \n",
    "    # Sanitize and sort inputs\n",
    "    left_df = left_df.reset_index(drop=True).sort_values(by=[by, left_on])\n",
    "    right_df = right_df.reset_index(drop=True).sort_values(by=[by, right_on])\n",
    "    \n",
    "    all_keys = left_df[by].unique()\n",
    "    merged_chunks = []\n",
    "    \n",
    "    for key in all_keys:\n",
    "        left_chunk = left_df[left_df[by] == key]\n",
    "        right_chunk = right_df[right_df[by] == key]\n",
    "        \n",
    "        merged_chunk = pd.merge_asof(\n",
    "            left=left_chunk,\n",
    "            right=right_chunk,\n",
    "            left_on=left_on,\n",
    "            right_on=right_on,\n",
    "            by=by,\n",
    "            direction='backward'\n",
    "        )\n",
    "        merged_chunks.append(merged_chunk)\n",
    "        \n",
    "    print(\"Robust merge successful.\")\n",
    "    return pd.concat(merged_chunks, ignore_index=True)\n",
    "\n",
    "# --- How to use it ---\n",
    "merged_df_1 = robust_merge_asof(\n",
    "     daily_prices_processed_df,\n",
    "     balance_sheet_processed_df,\n",
    "     left_on='trade_date',\n",
    "     right_on='f_ann_date',\n",
    "     by='ts_code'\n",
    ")\n",
    "\n",
    "merged_df_1.rename(columns={\n",
    "    'f_ann_date': 'balance_sheet_f_ann_date',\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "merged_df_2 = robust_merge_asof(\n",
    "     merged_df_1,\n",
    "     financial_indicators_processed_df,\n",
    "     left_on='trade_date',\n",
    "     right_on='ann_date',\n",
    "     by='ts_code'\n",
    ")\n",
    "merged_df_2.rename(columns={\n",
    "    'ann_date': 'financial_indicators_ann_date',\n",
    "}, inplace=True)\n",
    "\n",
    "final_merged_df = robust_merge_asof(\n",
    "     merged_df_2,\n",
    "     cashflow_processed_df,\n",
    "     left_on='trade_date',\n",
    "     right_on='f_ann_date',\n",
    "     by='ts_code'\n",
    ")\n",
    "final_merged_df.rename(columns={\n",
    "    'f_ann_date': 'cashflow_f_ann_date',\n",
    "}, inplace=True)    \n",
    "\n",
    "\n",
    "columns_to_drop = ['end_date_y','ann_date','end_date_x'] \n",
    "# The date columns from the right tables are redundant after the merge.\n",
    "# Pandas might add suffixes like _x, _y if column names conflict. Check final_merged_df.columns to be sure.\n",
    "\n",
    "# It's good practice to check for and remove potentially conflicting columns\n",
    "# For example, if 'f_ann_date' was in both balance_sheet and cashflow, it becomes f_ann_date_x and f_ann_date_y\n",
    "final_merged_df = final_merged_df.drop(columns=columns_to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "e45da0ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ts_code', 'trade_date', 'close', 'turnover_rate', 'pe_ttm', 'pb',\n",
       "       'total_mv', 'circ_mv', 'balance_sheet_f_ann_date', 'total_ncl',\n",
       "       'total_hldr_eqy_inc_min_int', 'financial_indicators_ann_date',\n",
       "       'debt_to_assets', 'q_sales_yoy', 'q_profit_yoy', 'cashflow_f_ann_date',\n",
       "       'end_date', 'n_cashflow_act'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "08184839",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "left keys must be sorted",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[179], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m merged_df_1 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge_asof\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mleft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdaily_prices_processed_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;66;43;03m# 日度数据作为左表\u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mright\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbalance_sheet_processed_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# 季度数据作为右表\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrade_date\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 左表的日期键\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mf_ann_date\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# 右表的日期键 (必须用公告日!)\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mby\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mts_code\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# 必须指定股票代码，确保数据在股票内部匹配\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbackward\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# 关键参数：'backward'表示对于每一行日度数据，向前(过去)寻找最近的财务数据\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.9/site-packages/pandas/core/reshape/merge.py:708\u001b[0m, in \u001b[0;36mmerge_asof\u001b[0;34m(left, right, on, left_on, right_on, left_index, right_index, by, left_by, right_by, suffixes, tolerance, allow_exact_matches, direction)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;124;03mPerform a merge by key distance.\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;124;03m4 2016-05-25 13:30:00.048   AAPL   98.00       100     NaN     NaN\u001b[39;00m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    691\u001b[0m op \u001b[38;5;241m=\u001b[39m _AsOfMerge(\n\u001b[1;32m    692\u001b[0m     left,\n\u001b[1;32m    693\u001b[0m     right,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    706\u001b[0m     direction\u001b[38;5;241m=\u001b[39mdirection,\n\u001b[1;32m    707\u001b[0m )\n\u001b[0;32m--> 708\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.9/site-packages/pandas/core/reshape/merge.py:1927\u001b[0m, in \u001b[0;36m_OrderedMerge.get_result\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_result\u001b[39m(\u001b[38;5;28mself\u001b[39m, copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m-> 1927\u001b[0m     join_index, left_indexer, right_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_join_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1929\u001b[0m     left_join_indexer: npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1930\u001b[0m     right_join_indexer: npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.9/site-packages/pandas/core/reshape/merge.py:1152\u001b[0m, in \u001b[0;36m_MergeOperation._get_join_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1148\u001b[0m     join_index, right_indexer, left_indexer \u001b[38;5;241m=\u001b[39m _left_join_on_index(\n\u001b[1;32m   1149\u001b[0m         right_ax, left_ax, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1152\u001b[0m     (left_indexer, right_indexer) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_join_indexers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_index:\n\u001b[1;32m   1155\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.9/site-packages/pandas/core/reshape/merge.py:2239\u001b[0m, in \u001b[0;36m_AsOfMerge._get_join_indexers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2236\u001b[0m         tolerance \u001b[38;5;241m=\u001b[39m tolerance\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m   2238\u001b[0m \u001b[38;5;66;03m# initial type conversion as needed\u001b[39;00m\n\u001b[0;32m-> 2239\u001b[0m left_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_values_for_libjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2240\u001b[0m right_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_values_for_libjoin(right_values, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2242\u001b[0m \u001b[38;5;66;03m# a \"by\" parameter requires special handling\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.9/site-packages/pandas/core/reshape/merge.py:2183\u001b[0m, in \u001b[0;36m_AsOfMerge._convert_values_for_libjoin\u001b[0;34m(self, values, side)\u001b[0m\n\u001b[1;32m   2181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m isna(values)\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   2182\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMerge keys contain null values on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mside\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m side\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2183\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mside\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m keys must be sorted\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, ArrowExtensionArray):\n\u001b[1;32m   2186\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39m_maybe_convert_datelike_array()\n",
      "\u001b[0;31mValueError\u001b[0m: left keys must be sorted"
     ]
    }
   ],
   "source": [
    "merged_df_1 = pd.merge_asof(\n",
    "    left=daily_prices_processed_df,               # 日度数据作为左表\n",
    "    right=balance_sheet_processed_df,          # 季度数据作为右表\n",
    "    left_on='trade_date',        # 左表的日期键\n",
    "    right_on='f_ann_date',         # 右表的日期键 (必须用公告日!)\n",
    "    by='ts_code',                # 必须指定股票代码，确保数据在股票内部匹配\n",
    "    direction='backward'         # 关键参数：'backward'表示对于每一行日度数据，向前(过去)寻找最近的财务数据\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b20c0629",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "left keys must be sorted",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[166], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m merged_df_1 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge_asof\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mleft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdaily_prices_processed_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;66;43;03m# 日度数据作为左表\u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mright\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbalance_sheet_processed_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# 季度数据作为右表\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrade_date\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 左表的日期键\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mf_ann_date\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# 右表的日期键 (必须用公告日!)\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mby\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mts_code\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# 必须指定股票代码，确保数据在股票内部匹配\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbackward\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# 关键参数：'backward'表示对于每一行日度数据，向前(过去)寻找最近的财务数据\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# --- 3. Second Merge: Result + Financial Indicators ---\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Now, merge the result with the financial indicators.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Note that the 'right_on' key changes to 'ann_date' for this DataFrame.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m merged_df_2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge_asof(\n\u001b[1;32m     14\u001b[0m     left\u001b[38;5;241m=\u001b[39mmerged_df_1,\n\u001b[1;32m     15\u001b[0m     right\u001b[38;5;241m=\u001b[39mfinancial_indicators_processed_df,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     20\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.9/site-packages/pandas/core/reshape/merge.py:708\u001b[0m, in \u001b[0;36mmerge_asof\u001b[0;34m(left, right, on, left_on, right_on, left_index, right_index, by, left_by, right_by, suffixes, tolerance, allow_exact_matches, direction)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;124;03mPerform a merge by key distance.\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;124;03m4 2016-05-25 13:30:00.048   AAPL   98.00       100     NaN     NaN\u001b[39;00m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    691\u001b[0m op \u001b[38;5;241m=\u001b[39m _AsOfMerge(\n\u001b[1;32m    692\u001b[0m     left,\n\u001b[1;32m    693\u001b[0m     right,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    706\u001b[0m     direction\u001b[38;5;241m=\u001b[39mdirection,\n\u001b[1;32m    707\u001b[0m )\n\u001b[0;32m--> 708\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.9/site-packages/pandas/core/reshape/merge.py:1927\u001b[0m, in \u001b[0;36m_OrderedMerge.get_result\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_result\u001b[39m(\u001b[38;5;28mself\u001b[39m, copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m-> 1927\u001b[0m     join_index, left_indexer, right_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_join_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1929\u001b[0m     left_join_indexer: npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1930\u001b[0m     right_join_indexer: npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.9/site-packages/pandas/core/reshape/merge.py:1152\u001b[0m, in \u001b[0;36m_MergeOperation._get_join_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1148\u001b[0m     join_index, right_indexer, left_indexer \u001b[38;5;241m=\u001b[39m _left_join_on_index(\n\u001b[1;32m   1149\u001b[0m         right_ax, left_ax, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1152\u001b[0m     (left_indexer, right_indexer) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_join_indexers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_index:\n\u001b[1;32m   1155\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.9/site-packages/pandas/core/reshape/merge.py:2239\u001b[0m, in \u001b[0;36m_AsOfMerge._get_join_indexers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2236\u001b[0m         tolerance \u001b[38;5;241m=\u001b[39m tolerance\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m   2238\u001b[0m \u001b[38;5;66;03m# initial type conversion as needed\u001b[39;00m\n\u001b[0;32m-> 2239\u001b[0m left_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_values_for_libjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2240\u001b[0m right_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_values_for_libjoin(right_values, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2242\u001b[0m \u001b[38;5;66;03m# a \"by\" parameter requires special handling\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.9/site-packages/pandas/core/reshape/merge.py:2183\u001b[0m, in \u001b[0;36m_AsOfMerge._convert_values_for_libjoin\u001b[0;34m(self, values, side)\u001b[0m\n\u001b[1;32m   2181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m isna(values)\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   2182\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMerge keys contain null values on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mside\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m side\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2183\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mside\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m keys must be sorted\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, ArrowExtensionArray):\n\u001b[1;32m   2186\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39m_maybe_convert_datelike_array()\n",
      "\u001b[0;31mValueError\u001b[0m: left keys must be sorted"
     ]
    }
   ],
   "source": [
    "merged_df_1 = pd.merge_asof(\n",
    "    left=daily_prices_processed_df,               # 日度数据作为左表\n",
    "    right=balance_sheet_processed_df,          # 季度数据作为右表\n",
    "    left_on='trade_date',        # 左表的日期键\n",
    "    right_on='f_ann_date',         # 右表的日期键 (必须用公告日!)\n",
    "    by='ts_code',                # 必须指定股票代码，确保数据在股票内部匹配\n",
    "    direction='backward'         # 关键参数：'backward'表示对于每一行日度数据，向前(过去)寻找最近的财务数据\n",
    ")\n",
    "\n",
    "# --- 3. Second Merge: Result + Financial Indicators ---\n",
    "# Now, merge the result with the financial indicators.\n",
    "# Note that the 'right_on' key changes to 'ann_date' for this DataFrame.\n",
    "merged_df_2 = pd.merge_asof(\n",
    "    left=merged_df_1,\n",
    "    right=financial_indicators_processed_df,\n",
    "    left_on='trade_date',\n",
    "    right_on='ann_date',    # Use the announcement date from financial indicators\n",
    "    by='ts_code',\n",
    "    direction='backward'\n",
    ")\n",
    "\n",
    "# --- 4. Final Merge: Result + Cash Flow ---\n",
    "# Finally, merge the result with the cash flow data.\n",
    "final_merged_df = pd.merge_asof(\n",
    "    left=merged_df_2,\n",
    "    right=cashflow_processed_df,\n",
    "    left_on='trade_date',\n",
    "    right_on='f_ann_date',  # Use the announcement date from the cash flow statement\n",
    "    by='ts_code',\n",
    "    direction='backward'\n",
    ")\n",
    "\n",
    "# The 'final_merged_df' now contains the combined data.\n",
    "# You might want to clean up the extra date columns from the right tables.\n",
    "columns_to_drop = ['f_ann_date_x', 'ann_date_x', 'f_ann_date_y','end_date_y','ann_date_y','end_date_x'] \n",
    "# The date columns from the right tables are redundant after the merge.\n",
    "# Pandas might add suffixes like _x, _y if column names conflict. Check final_merged_df.columns to be sure.\n",
    "\n",
    "# It's good practice to check for and remove potentially conflicting columns\n",
    "# For example, if 'f_ann_date' was in both balance_sheet and cashflow, it becomes f_ann_date_x and f_ann_date_y\n",
    "final_merged_df = final_merged_df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "641a145f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_df =  final_merged_df.sort_values(by=['ts_code', 'trade_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "15d877c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_code</th>\n",
       "      <th>trade_date</th>\n",
       "      <th>close</th>\n",
       "      <th>turnover_rate</th>\n",
       "      <th>pe_ttm</th>\n",
       "      <th>pb</th>\n",
       "      <th>total_mv</th>\n",
       "      <th>circ_mv</th>\n",
       "      <th>total_ncl</th>\n",
       "      <th>total_hldr_eqy_inc_min_int</th>\n",
       "      <th>debt_to_assets</th>\n",
       "      <th>q_sales_yoy</th>\n",
       "      <th>q_profit_yoy</th>\n",
       "      <th>end_date</th>\n",
       "      <th>n_cashflow_act</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>16.87</td>\n",
       "      <td>0.7885</td>\n",
       "      <td>11.6992</td>\n",
       "      <td>1.2210</td>\n",
       "      <td>3.273778e+07</td>\n",
       "      <td>3.273750e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.880730e+11</td>\n",
       "      <td>92.2304</td>\n",
       "      <td>19.3930</td>\n",
       "      <td>16.0079</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>8.448000e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>17.18</td>\n",
       "      <td>0.5752</td>\n",
       "      <td>11.9142</td>\n",
       "      <td>1.2434</td>\n",
       "      <td>3.333937e+07</td>\n",
       "      <td>3.333908e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.880730e+11</td>\n",
       "      <td>92.2304</td>\n",
       "      <td>19.3930</td>\n",
       "      <td>16.0079</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>8.448000e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>17.07</td>\n",
       "      <td>0.4442</td>\n",
       "      <td>11.8379</td>\n",
       "      <td>1.2355</td>\n",
       "      <td>3.312590e+07</td>\n",
       "      <td>3.312562e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.880730e+11</td>\n",
       "      <td>92.2304</td>\n",
       "      <td>19.3930</td>\n",
       "      <td>16.0079</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>8.448000e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>17.15</td>\n",
       "      <td>0.3755</td>\n",
       "      <td>11.8933</td>\n",
       "      <td>1.2413</td>\n",
       "      <td>3.328115e+07</td>\n",
       "      <td>3.328087e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.880730e+11</td>\n",
       "      <td>92.2304</td>\n",
       "      <td>19.3930</td>\n",
       "      <td>16.0079</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>8.448000e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>16.66</td>\n",
       "      <td>0.4369</td>\n",
       "      <td>11.5535</td>\n",
       "      <td>1.2058</td>\n",
       "      <td>3.233026e+07</td>\n",
       "      <td>3.232998e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.880730e+11</td>\n",
       "      <td>92.2304</td>\n",
       "      <td>19.3930</td>\n",
       "      <td>16.0079</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>8.448000e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403077</th>\n",
       "      <td>688981.SH</td>\n",
       "      <td>2025-10-13</td>\n",
       "      <td>136.47</td>\n",
       "      <td>7.0165</td>\n",
       "      <td>250.7944</td>\n",
       "      <td>7.2284</td>\n",
       "      <td>1.091770e+08</td>\n",
       "      <td>2.728803e+07</td>\n",
       "      <td>6.755544e+10</td>\n",
       "      <td>2.345195e+11</td>\n",
       "      <td>33.7830</td>\n",
       "      <td>17.3407</td>\n",
       "      <td>-12.1687</td>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>5.897793e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403572</th>\n",
       "      <td>688981.SH</td>\n",
       "      <td>2025-10-14</td>\n",
       "      <td>127.20</td>\n",
       "      <td>6.6065</td>\n",
       "      <td>233.7587</td>\n",
       "      <td>6.7374</td>\n",
       "      <td>1.017609e+08</td>\n",
       "      <td>2.543444e+07</td>\n",
       "      <td>6.755544e+10</td>\n",
       "      <td>2.345195e+11</td>\n",
       "      <td>33.7830</td>\n",
       "      <td>17.3407</td>\n",
       "      <td>-12.1687</td>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>5.897793e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403960</th>\n",
       "      <td>688981.SH</td>\n",
       "      <td>2025-10-15</td>\n",
       "      <td>129.56</td>\n",
       "      <td>4.0408</td>\n",
       "      <td>238.0957</td>\n",
       "      <td>6.8624</td>\n",
       "      <td>1.036489e+08</td>\n",
       "      <td>2.590633e+07</td>\n",
       "      <td>6.755544e+10</td>\n",
       "      <td>2.345195e+11</td>\n",
       "      <td>33.7830</td>\n",
       "      <td>17.3407</td>\n",
       "      <td>-12.1687</td>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>5.897793e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404225</th>\n",
       "      <td>688981.SH</td>\n",
       "      <td>2025-10-16</td>\n",
       "      <td>127.30</td>\n",
       "      <td>3.0622</td>\n",
       "      <td>233.9425</td>\n",
       "      <td>6.7427</td>\n",
       "      <td>1.018409e+08</td>\n",
       "      <td>2.545443e+07</td>\n",
       "      <td>6.755544e+10</td>\n",
       "      <td>2.345195e+11</td>\n",
       "      <td>33.7830</td>\n",
       "      <td>17.3407</td>\n",
       "      <td>-12.1687</td>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>5.897793e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404560</th>\n",
       "      <td>688981.SH</td>\n",
       "      <td>2025-10-17</td>\n",
       "      <td>121.98</td>\n",
       "      <td>4.1035</td>\n",
       "      <td>224.1658</td>\n",
       "      <td>6.4609</td>\n",
       "      <td>9.758487e+07</td>\n",
       "      <td>2.439066e+07</td>\n",
       "      <td>6.755544e+10</td>\n",
       "      <td>2.345195e+11</td>\n",
       "      <td>33.7830</td>\n",
       "      <td>17.3407</td>\n",
       "      <td>-12.1687</td>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>5.897793e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404561 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ts_code trade_date   close  turnover_rate    pe_ttm      pb  \\\n",
       "0       000001.SZ 2020-01-02   16.87         0.7885   11.6992  1.2210   \n",
       "318     000001.SZ 2020-01-03   17.18         0.5752   11.9142  1.2434   \n",
       "602     000001.SZ 2020-01-06   17.07         0.4442   11.8379  1.2355   \n",
       "806     000001.SZ 2020-01-07   17.15         0.3755   11.8933  1.2413   \n",
       "1189    000001.SZ 2020-01-08   16.66         0.4369   11.5535  1.2058   \n",
       "...           ...        ...     ...            ...       ...     ...   \n",
       "403077  688981.SH 2025-10-13  136.47         7.0165  250.7944  7.2284   \n",
       "403572  688981.SH 2025-10-14  127.20         6.6065  233.7587  6.7374   \n",
       "403960  688981.SH 2025-10-15  129.56         4.0408  238.0957  6.8624   \n",
       "404225  688981.SH 2025-10-16  127.30         3.0622  233.9425  6.7427   \n",
       "404560  688981.SH 2025-10-17  121.98         4.1035  224.1658  6.4609   \n",
       "\n",
       "            total_mv       circ_mv     total_ncl  total_hldr_eqy_inc_min_int  \\\n",
       "0       3.273778e+07  3.273750e+07           NaN                2.880730e+11   \n",
       "318     3.333937e+07  3.333908e+07           NaN                2.880730e+11   \n",
       "602     3.312590e+07  3.312562e+07           NaN                2.880730e+11   \n",
       "806     3.328115e+07  3.328087e+07           NaN                2.880730e+11   \n",
       "1189    3.233026e+07  3.232998e+07           NaN                2.880730e+11   \n",
       "...              ...           ...           ...                         ...   \n",
       "403077  1.091770e+08  2.728803e+07  6.755544e+10                2.345195e+11   \n",
       "403572  1.017609e+08  2.543444e+07  6.755544e+10                2.345195e+11   \n",
       "403960  1.036489e+08  2.590633e+07  6.755544e+10                2.345195e+11   \n",
       "404225  1.018409e+08  2.545443e+07  6.755544e+10                2.345195e+11   \n",
       "404560  9.758487e+07  2.439066e+07  6.755544e+10                2.345195e+11   \n",
       "\n",
       "        debt_to_assets  q_sales_yoy  q_profit_yoy   end_date  n_cashflow_act  \n",
       "0              92.2304      19.3930       16.0079 2019-09-30    8.448000e+10  \n",
       "318            92.2304      19.3930       16.0079 2019-09-30    8.448000e+10  \n",
       "602            92.2304      19.3930       16.0079 2019-09-30    8.448000e+10  \n",
       "806            92.2304      19.3930       16.0079 2019-09-30    8.448000e+10  \n",
       "1189           92.2304      19.3930       16.0079 2019-09-30    8.448000e+10  \n",
       "...                ...          ...           ...        ...             ...  \n",
       "403077         33.7830      17.3407      -12.1687 2025-06-30    5.897793e+09  \n",
       "403572         33.7830      17.3407      -12.1687 2025-06-30    5.897793e+09  \n",
       "403960         33.7830      17.3407      -12.1687 2025-06-30    5.897793e+09  \n",
       "404225         33.7830      17.3407      -12.1687 2025-06-30    5.897793e+09  \n",
       "404560         33.7830      17.3407      -12.1687 2025-06-30    5.897793e+09  \n",
       "\n",
       "[404561 rows x 15 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d9d4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在从 'sw_industries' 加载数据...\n",
      "-> 成功加载 3,000 行数据。\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "ee8cd1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在从 'sw_industries' 加载数据...\n",
      "-> 成功加载 5,724 行数据。\n"
     ]
    }
   ],
   "source": [
    "sw_industry_query = {}\n",
    "sw_industry_projection = {\n",
    "    \"ts_code\": 1,\n",
    "    \"l1_code\": 1,\n",
    "    \"l1_name\": 1,\n",
    "    \"in_date\": 1,\n",
    "    \"out_date\": 1,\n",
    "    \"is_new\": 1,\n",
    "    \"_id\": 0\n",
    "}\n",
    "\n",
    "sw_industry_data = load_collection_to_df(db, 'sw_industries', {}, sw_industry_projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "f60d6339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l1_code</th>\n",
       "      <th>l1_name</th>\n",
       "      <th>ts_code</th>\n",
       "      <th>in_date</th>\n",
       "      <th>out_date</th>\n",
       "      <th>is_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>801150.SI</td>\n",
       "      <td>医药生物</td>\n",
       "      <td>688068.SH</td>\n",
       "      <td>20190911</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>801140.SI</td>\n",
       "      <td>轻工制造</td>\n",
       "      <td>002862.SZ</td>\n",
       "      <td>20170330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>801080.SI</td>\n",
       "      <td>电子</td>\n",
       "      <td>300408.SZ</td>\n",
       "      <td>20140127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>801710.SI</td>\n",
       "      <td>建筑材料</td>\n",
       "      <td>600819.SH</td>\n",
       "      <td>19940128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>801880.SI</td>\n",
       "      <td>汽车</td>\n",
       "      <td>300580.SZ</td>\n",
       "      <td>20161212</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5719</th>\n",
       "      <td>801080.SI</td>\n",
       "      <td>电子</td>\n",
       "      <td>600074.SH</td>\n",
       "      <td>20150401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5720</th>\n",
       "      <td>801740.SI</td>\n",
       "      <td>国防军工</td>\n",
       "      <td>600677.SH</td>\n",
       "      <td>20070702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5721</th>\n",
       "      <td>801770.SI</td>\n",
       "      <td>通信</td>\n",
       "      <td>600485.SH</td>\n",
       "      <td>20030804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5722</th>\n",
       "      <td>801180.SI</td>\n",
       "      <td>房地产</td>\n",
       "      <td>600240.SH</td>\n",
       "      <td>20000628</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5723</th>\n",
       "      <td>801720.SI</td>\n",
       "      <td>建筑装饰</td>\n",
       "      <td>000018.SZ</td>\n",
       "      <td>20180713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5724 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        l1_code l1_name    ts_code   in_date  out_date is_new\n",
       "0     801150.SI    医药生物  688068.SH  20190911       NaN      Y\n",
       "1     801140.SI    轻工制造  002862.SZ  20170330       NaN      Y\n",
       "2     801080.SI      电子  300408.SZ  20140127       NaN      Y\n",
       "3     801710.SI    建筑材料  600819.SH  19940128       NaN      Y\n",
       "4     801880.SI      汽车  300580.SZ  20161212       NaN      Y\n",
       "...         ...     ...        ...       ...       ...    ...\n",
       "5719  801080.SI      电子  600074.SH  20150401       NaN      Y\n",
       "5720  801740.SI    国防军工  600677.SH  20070702       NaN      Y\n",
       "5721  801770.SI      通信  600485.SH  20030804       NaN      Y\n",
       "5722  801180.SI     房地产  600240.SH  20000628       NaN      Y\n",
       "5723  801720.SI    建筑装饰  000018.SZ  20180713       NaN      Y\n",
       "\n",
       "[5724 rows x 6 columns]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw_industry_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "7381838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Barra_factor_cal/data/stk_sw_industry.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "2c191f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l1_code</th>\n",
       "      <th>l1_name</th>\n",
       "      <th>ts_code</th>\n",
       "      <th>name</th>\n",
       "      <th>in_date</th>\n",
       "      <th>out_date</th>\n",
       "      <th>is_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>801150.SI</td>\n",
       "      <td>医药生物</td>\n",
       "      <td>688068.SH</td>\n",
       "      <td>热景生物</td>\n",
       "      <td>20190911</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>801140.SI</td>\n",
       "      <td>轻工制造</td>\n",
       "      <td>002862.SZ</td>\n",
       "      <td>实丰文化</td>\n",
       "      <td>20170330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>801080.SI</td>\n",
       "      <td>电子</td>\n",
       "      <td>300408.SZ</td>\n",
       "      <td>三环集团</td>\n",
       "      <td>20140127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>801710.SI</td>\n",
       "      <td>建筑材料</td>\n",
       "      <td>600819.SH</td>\n",
       "      <td>耀皮玻璃</td>\n",
       "      <td>19940128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>801880.SI</td>\n",
       "      <td>汽车</td>\n",
       "      <td>300580.SZ</td>\n",
       "      <td>贝斯特</td>\n",
       "      <td>20161212</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5719</th>\n",
       "      <td>801080.SI</td>\n",
       "      <td>电子</td>\n",
       "      <td>600074.SH</td>\n",
       "      <td>退市保千(退市)</td>\n",
       "      <td>20150401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5720</th>\n",
       "      <td>801740.SI</td>\n",
       "      <td>国防军工</td>\n",
       "      <td>600677.SH</td>\n",
       "      <td>*ST航通(退市)</td>\n",
       "      <td>20070702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5721</th>\n",
       "      <td>801770.SI</td>\n",
       "      <td>通信</td>\n",
       "      <td>600485.SH</td>\n",
       "      <td>*ST信威(退市)</td>\n",
       "      <td>20030804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5722</th>\n",
       "      <td>801180.SI</td>\n",
       "      <td>房地产</td>\n",
       "      <td>600240.SH</td>\n",
       "      <td>退市华业(退市)</td>\n",
       "      <td>20000628</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5723</th>\n",
       "      <td>801720.SI</td>\n",
       "      <td>建筑装饰</td>\n",
       "      <td>000018.SZ</td>\n",
       "      <td>神城A退(退市)</td>\n",
       "      <td>20180713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5724 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        l1_code l1_name    ts_code       name   in_date  out_date is_new\n",
       "0     801150.SI    医药生物  688068.SH       热景生物  20190911       NaN      Y\n",
       "1     801140.SI    轻工制造  002862.SZ       实丰文化  20170330       NaN      Y\n",
       "2     801080.SI      电子  300408.SZ       三环集团  20140127       NaN      Y\n",
       "3     801710.SI    建筑材料  600819.SH       耀皮玻璃  19940128       NaN      Y\n",
       "4     801880.SI      汽车  300580.SZ        贝斯特  20161212       NaN      Y\n",
       "...         ...     ...        ...        ...       ...       ...    ...\n",
       "5719  801080.SI      电子  600074.SH   退市保千(退市)  20150401       NaN      Y\n",
       "5720  801740.SI    国防军工  600677.SH  *ST航通(退市)  20070702       NaN      Y\n",
       "5721  801770.SI      通信  600485.SH  *ST信威(退市)  20030804       NaN      Y\n",
       "5722  801180.SI     房地产  600240.SH   退市华业(退市)  20000628       NaN      Y\n",
       "5723  801720.SI    建筑装饰  000018.SZ   神城A退(退市)  20180713       NaN      Y\n",
       "\n",
       "[5724 rows x 7 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
